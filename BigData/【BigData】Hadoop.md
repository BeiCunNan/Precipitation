# ã€BigDataã€‘Hadoop

<font color=#ff9f43>Importance</font>

<font color=#FD7272>Importance</font>

<font color=#00d2d3>Importance</font>



## ä¸€ ã€Overview

###  2.1 Big Data

å››ä¸ªç‰¹ç‚¹ï¼š4V

ç¼–ç¨‹

## äºŒ HDFS

### 2.1 Overview

#### 2.1.1 WWH

éšç€æ•°æ®é‡çš„å¢å¤šï¼Œéœ€è¦å°†æ•°æ®å­˜å‚¨åˆ°ä¸åŒçš„OSä¸­ï¼Œéœ€è¦ä½¿ç”¨åˆ°<font color=#ff9f43>åˆ†å¸ƒå¼æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ</font>ï¼ŒHDFS(Hadoop Distributed File System)å°±æ˜¯ä¸€ç§åˆ†å¸ƒå¼æ–‡ä»¶ç®¡ç†ç³»ç»Ÿï¼Œç”¨æ¥<font color=#ff9f43>å­˜å‚¨ã€ç®¡ç†</font>æ–‡ä»¶ã€‚é€‚åˆä¸€æ¬¡æ€§è¯»å…¥ï¼Œå¤šæ¬¡è¯»å‡ºçš„åœºæ™¯



#### 2.1.2 Advantages

- é«˜å®¹é”™æ€§ï¼šæ•°æ®è‡ªåŠ¨ä¿å­˜å¤šä¸ªå‰¯æœ¬ï¼Œä¸¢æ‰ä¸€ä¸ªå‰¯æœ¬åå¯è‡ªåŠ¨æ¢å¤
- é€‚åˆå¤„ç†å¤§æ•°æ®ï¼šèƒ½å¤Ÿå¤„ç†PBçº§å’Œç™¾ä¸‡è§„æ¨¡ä»¥ä¸Šçš„æ–‡ä»¶æ•°é‡
- æˆæœ¬ä½ï¼šæ„å»ºåœ¨å»‰ä»·æœºå™¨ä¸Š



#### 2.1.3 Disadvantage

- ä¸é€‚åˆä½æ—¶å»¶æ•°æ®è®¿é—®
- æ— æ³•é«˜æ•ˆçš„å¯¹å¤§é‡å°æ–‡ä»¶è¿›è¡Œå­˜å‚¨ï¼šæ— è®ºå¤§æ–‡ä»¶è¿˜æ˜¯å°æ–‡ä»¶éƒ½éœ€è¦NameNodeæ¥å­˜å‚¨ç›®å½•å’Œå—ä¿¡æ¯ï¼Œå¯¹äºå°æ–‡ä»¶æ¥è¯´èµ„æºå…¶å®æ˜¯å¾ˆæµªè´¹çš„
- ä¸æ”¯æŒå¹¶å‘å†™å…¥ã€æ–‡ä»¶éšæœºä¿®æ”¹ï¼šä»…æ”¯æŒæ•°æ®appendè¿½åŠ 



#### 2.1.4 Compose

**NameNode(NN)**ï¼šå­˜å‚¨æ–‡ä»¶çš„<font color=#ff9f43>å…ƒæ•°æ®</font>ï¼Œå¦‚æ–‡ä»¶åã€æ–‡ä»¶ç›®å½•ç»“æ„ã€æ–‡ä»¶å±æ€§ï¼ˆç”Ÿæˆæ—¶é—´ã€å‰¯æœ¬æ•°ã€æ–‡ä»¶æƒé™ï¼‰ä»¥åŠæ¯ä¸ªæ–‡ä»¶çš„<font color=#ff9f43>å—åˆ—è¡¨</font>å’Œå—æ‰€åœ¨çš„DataNodeç­‰

**DataNode(DN)**ï¼šåœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨æ–‡ä»¶å—æ•°æ®ä»¥åŠå—æ•°æ®çš„æ ¡éªŒå’Œï¼Œæ‰§è¡Œæ•°æ®å—çš„è¯»/å†™æ“ä½œ

**Secondary NameNode(2NN)**ï¼šå°ç§˜ä¹¦ï¼Œæ¯éš”ä¸€æ®µæ—¶é—´å¯¹NameNodeå…ƒæ•°æ®è¿›è¡Œå¤‡ä»½ï¼ˆä¸æ˜¯çƒ­å¤‡ä»½ï¼‰ï¼Œè‹¥NNæŒ‚æ‰äº†ï¼Œéœ€è¦ä¸€æ®µæ—¶å€™æ¥æ›¿æ¢NN

NNä¸‹è¾¾æŒ‡ä»¤ï¼ŒDNè¿›è¡Œå®é™…æ“ä½œ

![image-20221226221619173](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221226221619173.png)

#### 2.1.5 File block

Hadoop2.Xå’ŒHadoop3.Xéƒ½æ˜¯128Mbï¼ŒHadoop1.Xæ˜¯64Mb

ä¸ºä»€ä¹ˆå—çš„å¤§å°æ—¢ä¸èƒ½è®¾ç½®å¤ªå°ä¹Ÿä¸èƒ½è®¾ç½®å¤ªå¤§å‘¢ï¼Ÿ

- è‹¥è®¾ç½®å¤ªå°ï¼Œå¢åŠ äº†å¯»å€æ—¶é—´
- è‹¥è®¾ç½®å¤ªå¤§ï¼Œè®¡ç®—æœºä¼ è¾“é€Ÿåº¦å’Œå¤„ç†é€Ÿåº¦è¿‡æ…¢
- <font color=#ff9f43>å¤§å°å–å†³äºä½ è®¡ç®—æœºæœ¬èº«çš„ä¼ è¾“é€Ÿç‡</font>



### 2.2 Shell

#### 2.2.1 Basic grammer

hdfs fs -[operation]

hdfs hds -[operation]



#### 2.2.2 Common commands

| Create File |                                                           |
| ----------- | --------------------------------------------------------- |
|             | [root@hadoop102 hadoop-3.1.3]# `hadoop fs -mkdir /sanguo` |



| Upload File                                                  |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| æ–¹å¼ä¸€ï¼š -moveæœ¬åœ°<font color=#ff9f43>å‰ªåˆ‡</font>ç²˜è´´åˆ°HDFS  | [root@hadoop104 hadoop-3.1.3]# `hadoop fs -moveFromLocal ./shuguo.txt /sanguo` |
| æ–¹å¼äºŒï¼šæœ¬åœ°<font color=#ff9f43>æ‹·è´</font>åˆ°HDFS            | [root@hadoop104 hadoop-3.1.3]# `hadoop fs -copyFromLocal weiguo.txt /sanguo` |
| æ–¹å¼ä¸‰ï¼šç­‰åŒäº<font color=#ff9f43>æ‹·è´</font>ï¼Œ<font color=#ff9f43>ç”Ÿäº§ç¯å¢ƒ</font>æ›´ä¹ æƒ¯ç”¨è¿™ä¸ªï¼Œå› ä¸ºçŸ­å°ç²¾æ‚ | [root@hadoop104 hadoop-3.1.3]# `hadoop fs -put ./wuguo.txt /sanguo` |
| æ–¹å¼å››ï¼š<font color=#ff9f43>è¿½åŠ </font>                      | [root@hadoop104 hadoop-3.1.3]# `hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt` |



| Download File                                                |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| æ–¹å¼ä¸€ï¼šä»HDFSæ‹·è´åˆ°æœ¬åœ°                                     | [root@hadoop104 hadoop-3.1.3]# `hadoop fs -copyToLocal /sanguo/shuguo.txt ./` |
| æ–¹å¼äºŒï¼šç­‰åŒäº<font color=#ff9f43>æ‹·è´</font>ï¼Œ<font color=#ff9f43>ç”Ÿäº§ç¯å¢ƒ</font>æ›´ä¹ æƒ¯ç”¨è¿™ä¸ªï¼ŒçŸ­å°ç²¾æ‚ï¼Œå¯ä»¥<font color=#ff9f43>ä¿®æ”¹æ–‡ä»¶åå­—</font> | [root@hadoop104 hadoop-3.1.3]# `hadoop fs -get /sanguo/shuguo.txt ./shuguo2.txt` |



[root@hadoop104 hadoop-3.1.3]# hadoop fs -[operation]

Hadoopä¸Linuxçš„æŒ‡ä»¤å·®ä¸å¤šï¼ŒåŒºåˆ«å°¤å…¶æ³¨æ„æ¯ä¸ªoperationä¹‹å‰éƒ½è¦åŠ  <font color=#ff9f43>-</font>

| Other Operation       |                                                              |
| :-------------------- | ------------------------------------------------------------ |
| -ls                   | æ˜¾ç¤ºç›¸å…³ä¿¡æ¯                                                 |
| -cat                  | æ˜¾ç¤ºæ–‡ä»¶å†…å®¹                                                 |
| -chgrpã€-chmodã€chown | ä¿®æ”¹æ–‡ä»¶æƒé™                                                 |
| -cp                   | æ‹·è´æ–‡ä»¶                                                     |
| -mv                   | ç§»åŠ¨æ–‡ä»¶                                                     |
| -tail                 | æ˜¾ç¤ºä¸€ä¸ªæ–‡ä»¶çš„æœ«å°¾1kbçš„æ•°æ®                                  |
| -rm                   | åˆ é™¤æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹                                             |
| -rm -r                | é€’å½’åˆ é™¤ç›®å½•å’Œç›®å½•ä¸­çš„å†…å®¹                                   |
| -du                   | ç»Ÿè®¡æ–‡ä»¶å¤¹çš„å¤§å°![image-20221231111230197](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231111230197.png)è¿™é‡Œæœ‰ä¸¤åˆ—æ•°æ®ï¼Œå·¦è¾¹ä¸€åˆ—æ˜¯è¡¨ç¤ºæœ¬æ–‡ä»¶çš„å¤§å°ï¼Œå³è¾¹ä¸€åˆ—å› ä¸ºé›†ç¾¤æ­å»ºäº†ä¸‰å°è®¾å¤‡ï¼Œå› æ­¤æœ‰ä¸‰ä¸ªå‰¯æœ¬ |
| -setrep               | è®¾ç½®HDFSä¸­æ–‡ä»¶çš„å‰¯æœ¬æ•°é‡è¿™é‡Œ                                                                                                                                          æˆ‘è®¾ç½®äº†shuguo.txtçš„å‰¯æœ¬æ•°é‡ä¸º10ï¼Œåœ¨HDFSä¸­å¯ä»¥çœ‹åˆ°æ˜¯10ï¼Œä½†æ˜¯å› ä¸ºæˆ‘ä»¬å®é™…ä¸Šåªæœ‰ä¸‰å°ä¸»æœºï¼ˆå³3ä¸ªDataNodeï¼‰ï¼Œå› æ­¤å®é™…ä¸Šåªæœ‰3ä¸ªå‰¯æœ¬ã€‚å› æ­¤è¿™é‡Œçš„10åªæ˜¯NameNodeè®°å½•çš„æ•°æ®ï¼Œå®é™…å¾—çœ‹DataNode |

æ­¤å¤–ï¼Œåœ¨å®é™…æ“ä½œä¸­ï¼Œå¯ä»¥åœ¨<font color=#ff9f43>hadoop/bin</font>ç›®å½•ä¸‹ä½¿ç”¨`./hdfs dfs -put æ–‡ä»¶A ç›®å½•B` å®ç°å°†æ–‡ä»¶Aä¸Šä¼ åˆ°hadoopçš„Bç›®å½•ä¸‹



### 2.3 API

è‹¥åœ¨XShellä¸­æ“ä½œï¼Œå…¶å®å®é™…ä¸Šæ˜¯åœ¨Hadoop103<font color=#ff9f43>å†…éƒ¨</font>æ“ä½œï¼Œè€ŒWindowsæ˜¯å®¢æˆ·ç«¯ï¼Œæ˜¯Hadoopçš„<font color=#ff9f43>å¤–éƒ¨</font>æ“ä½œï¼Œå› æ­¤Hadoopéœ€è¦æä¾›ä¸€äº›<font color=#ff9f43>API</font>ç»™å¤–éƒ¨

<img src="https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231111635184.png" alt="image-20221231111635184" style="zoom:80%;" />

#### 2.3.1 Configuration in IDEAL

é…ç½®xmlæ–‡ä»¶

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>3.1.3</version>
    </dependency>

    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.13.2</version>
        <scope>test</scope>
    </dependency>
    
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-log4j12</artifactId>
        <version>1.7.36</version>
        <scope>test</scope>
    </dependency>
</dependencies>
```

ç¼–å†™log4j.proprtiesæ—¥å¿—æ–‡ä»¶

```properties
log4j.rootLogger=INFO, stdout 
log4j.appender.stdout=org.apache.log4j.ConsoleAppender 
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout 
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n 
log4j.appender.logfile=org.apache.log4j.FileAppender 
log4j.appender.logfile.File=target/spring.log 
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout 
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n
```

åˆ›å»ºcom.bcn.hdfsæ–‡ä»¶å¤¹ï¼Œéšåå°±å¯ä»¥åœ¨æ–‡ä»¶å¤¹ä¸­åˆ›å»ºå„ç§å„æ ·çš„æ–‡ä»¶äº†



#### 2.3.2 Routineï¼ˆå¥—è·¯ï¼‰

1. è·å–èµ„æºï¼ˆå®¢æˆ·ç«¯å¯¹è±¡ï¼‰
2. æ‰§è¡Œæ“ä½œ
3. å…³é—­èµ„æº

valpeopleDF=spark.sparkContext.textFile("hdfs://hadoop102:8020/input/people.txt").map(_.split(",")).map(attributes=>Person(attributes(0),attributes(1).trim().toInt)).toDF()



#### 2.3.3 Example -- File operation

**File Create Download Delete Rename Move Detail**

```java
package com.bcn.hdfs;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;

/**
 * @author å¤§ç™½èœ
 * @date Created in 2022/7/22 18:50
 */

public class HdfsClient {
    private FileSystem fs;

    @Before
    public void init() throws URISyntaxException, IOException, InterruptedException {
        // è¿æ¥é›†ç¾¤åœ°å€
        URI uri = new URI("hdfs://hadoop102:8020");
        // åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶
        Configuration configuration=new Configuration();
        // ç”¨æˆ·
        String user="root";
        // è·å–å®¢æˆ·ç«¯å¯¹è±¡
        fs = FileSystem.get(uri,configuration,user);
    }

    @After
    public void close() throws IOException {
        fs.close();
    }

    @Test
    public void testmkdir() throws IOException {
        // åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹
        fs.mkdirs(new Path("/xiyouji/huaguoshan1"));
    }
}

// ä¸Šä¼ æ–‡ä»¶
@Test
public void testPut() therows IOException {
    // å‚æ•°ä¸€ï¼šæ˜¯å¦åˆ é™¤åŸæ•°æ®
    // å‚æ•°äºŒï¼šæ˜¯å¦å…è®¸è¦†ç›–
    // å‚æ•°ä¸‰ï¼šåŸæ•°æ®è·¯å¾„
    // å‚æ•°å››ï¼šç›®çš„æ•°æ®è·¯å¾„
    fs.copyFromLocalFile(false,false,new Path("E:\\Hadoop and Spark\\TestData\\sunhukong.txt"),new Path("hdfs://hadoop102/xiyouji/hauguoshan1"));
}

//æ–‡ä»¶ä¸‹è½½
@Test
public void testGet() throws IOException {
    // å‚æ•°ä¸€ï¼šæ˜¯å¦åˆ é™¤åŸæ–‡ä»¶,å‚æ•°äºŒï¼šåŸæ–‡ä»¶è·¯å¾„HDFS,å‚æ•°ä¸‰ï¼šç›®çš„åœ°å€Win,å‚æ•°å››:æœ¬åœ°æ˜¯å¦å¼€å¯æ ¡éªŒ
    fs.copyToLocalFile(false,new Path("hdfs://hadoop102/xiyouji/huaguoshan1"),new Path("E:\\Hadoop and Spark"),false);
}

// åˆ é™¤æ–‡ä»¶
@Test
public void testDel() throws IOException {
    // å‚æ•°ä¸€ï¼šè¦åˆ é™¤çš„è·¯å¾„,å‚æ•°äºŒï¼šæ˜¯å¦é€’å½’åˆ é™¤\
    // åˆ é™¤æ–‡ä»¶
    fs.delete(new Path("hdfs://hadoop102/xiyouji/hauguoshan"),false);
    //åˆ é™¤ç©ºç›®å½•
    fs.delete(new Path("hdfs://hadoop102/xiyouji"),false);
    //åˆ é™¤éç©ºç›®å½•
    fs.delete(new Path("hdfs://hadoop102/xiyouji"),true);
}

// æ–‡ä»¶æ”¹åå’Œç§»åŠ¨ï¼ˆæ˜¯åŒæ—¶å‘ç”Ÿçš„ï¼‰
@Test
public void testmv() throws IOException {
    //å‚æ•°ä¸€ï¼šåŸæ–‡ä»¶åœ°å€ï¼Œå‚æ•°äºŒï¼šç›®æ ‡æ–‡ä»¶åœ°å€
    fs.rename(new Path("hdfs://hadoop102/xiyouji/hauguoshan"),new Path("hdfs://hadoop102/xiyouji/huaguoshan"));
}

// æ–‡ä»¶è¯¦ç»†ä¿¡æ¯æŸ¥çœ‹
@Test
public void testFileDetails() throws IOException {
   // è·å–æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
    RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path("/"),true);

    // éå†æ–‡ä»¶
    while(listFiles.hasNext()) {
        LocatedFileStatus fileStatus = listFiles.next();
        System.out.println("========"+fileStatus.getPath()+"========");
        System.out.println(fileStatus.getOwner());
        System.out.println(fileStatus.getGroup());
        System.out.println(fileStatus.getLen());
        System.out.println(fileStatus.getModificationTime());
        System.out.println(fileStatus.getReplication());
        System.out.println(fileStatus.getBlockSize());
        System.out.println(fileStatus.getPath().getName());
    }
}

```



## ğŸ”¥2.4 Read and Write

#### 2.4.1 Write data

æ€»ä½“æµç¨‹

- å»ºç«‹è¿æ¥
- å»ºç«‹ä¼ è¾“é€šé“
- æ­£å¼ä¼ è¾“æ•°æ®

**å»ºç«‹è¿æ¥**ï¼šç±»ä¼¼è®¡ç½‘ä¸­çš„å››æ¬¡æ¡æ‰‹

<font color=#ff9f43>Distributed FileStyle</font>ï¼šåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œåç»­ä¸NameNodeå»ºç«‹è¿æ¥çš„è°ˆåˆ¤ä»£è¡¨äºº

<font color=#ff9f43>FSDataOutStream</font>ï¼šæ•°æ®æµå¯¹è±¡ï¼Œä½œä¸ºæ•°æ®å…·ä½“çš„ä¼ è¾“ä»‹è´¨

<img src="https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231145928966.png" alt="image-20221231145928966" style="zoom: 33%;" />



**å»ºç«‹ä¼ è¾“é€šé“**ï¼šå°±è¿‘åŸåˆ™ï¼Œç¦»å“ªä¸ªDataNodeè¿‘ï¼Œå°±å…ˆå’Œå“ªä¸ªDataNodeå»ºç«‹é€šé“è¿æ¥

![image-20221231150030260](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231150030260.png)

**æ­£å¼ä¼ è¾“æ•°æ®**

<font color=#ff9f43>æœ€å°</font>ä¼ è¾“å•ä½æ˜¯<font color=#ff9f43>chunk</font>ï¼Œä¸€ä¸ªä¸€ä¸ªchunkç»„æˆä¸€ä¸ª<font color=#ff9f43>åŸºæœ¬</font>ä¼ è¾“å•ä½<font color=#ff9f43>Packet</font>

ä¼ è¾“çš„æ–¹å¼æ˜¯å¹¶è¡Œ+ä¸²è¡Œï¼šä¸€ä¸ªä¸ªPacketä¼ è¾“åˆ°DataNodeä¸­ï¼Œä¼ è¾“å®Œæ¯•é©¬ä¸Šåˆ°ä¸‹ä¸€ä¸ªDataNodeï¼ŒåŠå’Œè®¡ç½‘ä¸­çš„TCPçš„æµæ°´çº¿å¼ä¼ è¾“æ–¹å¼ä¸€æ ·

![image-20221231150229078](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231150229078.png)



#### 2.4.2 Network topology

ç½‘ç»œæ‹“æ‰‘--èŠ‚ç‚¹è·ç¦»è®¡ç®—

æœºæ¶ï¼šç‰©ç†ä¸Šå°±æ˜¯æœºæˆ¿é‡Œå¯ä»¥æ”¾å¾ˆå¤šæœåŠ¡å™¨çš„é“çš®æ¶å­

![image-20221231150530848](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231150530848.png)

åœ¨HDFSå†™æ•°æ®çš„è¿‡ç¨‹ä¸­ï¼Œä¸Šä¼ æ•°æ®çš„ä¸»æœºä¼šé€‰æ‹©ç¦»è‡ªå·±æœ€è¿‘çš„DataNodeä¸Šä¼ æ•°æ®ï¼Œé‚£ä¹ˆè¿™ä¸ªæœ€è¿‘è·ç¦»æ€ä¹ˆè®¡ç®—å‘¢ï¼Ÿ

**èŠ‚ç‚¹è·ç¦»**ï¼šä¸¤ä¸ªç»“ç‚¹åˆ°è¾¾<font color=#ff9f43>æœ€è¿‘</font>çš„<font color=#ff9f43>å…±åŒç¥–å…ˆ</font>çš„è·ç¦»æ€»å’Œ

1. åŒä¸€ç»“ç‚¹ä¸Šçš„è¿›ç¨‹ï¼Œè‡ªå·±å’Œè‡ªå·±çš„ç¥–å…ˆå½“ç„¶ä¹Ÿæ˜¯è‡ªå·±ï¼Œè·ç¦»è‡ªç„¶æ˜¯0
2. ä¸åŒæ•°æ®ä¸­å¿ƒçš„èŠ‚ç‚¹ï¼šè·³æœºæ¶ä¸º1ï¼Œè·³é›†ç¾¤ä¸º1ï¼Œè·³äº’åˆ©ç½‘ï¼ˆæ©™è‰²çš„å†…å®¹ï¼‰ä¸º1ï¼Œæ€»å…±ä¸º3ï¼Œä¸¤ä¸ªèŠ‚ç‚¹è‡ªç„¶å°±æ˜¯6

![image-20221231150645853](C:\Users\å¤§ç™½èœ\AppData\Roaming\Typora\typora-user-images\image-20221231150645853.png)

#### 2.4.3 Rack awareï¼ˆæœºæ¶æ„ŸçŸ¥ï¼‰

ä½œç”¨ï¼šå‰¯æœ¬å­˜å‚¨èŠ‚ç‚¹é€‰æ‹©

![image-20221231150651770](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231150651770.png)

ä¸‰ä¸ªèŠ‚ç‚¹å­˜å‚¨çš„ç­–ç•¥å¦‚ä¸‹

1. ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å­˜å‚¨åœ¨æœ¬åœ°ï¼Œä¿è¯ä¸€ä¸ªæ•°æ®<font color=#ff9f43>æœ€å¿«</font>
2. ç¬¬äºŒä¸ªå­˜å‚¨åœ¨å¦ä¸€ä¸ªæœºæ¶ï¼Œä¿è¯æ•°æ®<font color=#ff9f43>å¯é æ€§</font>
3. ç¬¬ä¸‰ä¸ªå­˜å‚¨åœ¨ç¬¬äºŒä¸ªèŠ‚ç‚¹çš„æœºæ¶ä¸Šï¼Œä¿è¯åç»­æ•°æ®<font color=#ff9f43>ä¼ è¾“æ•ˆç‡</font>

![image-20221231150737399](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231150737399.png)

#### 2.4.4 Read data

è¯»å–æ˜¯æŒ‰ç…§å…ƒæ•°æ®ä¸­å­˜å‚¨çš„å†…å®¹ï¼Œä¸€ä¸ªä¸€ä¸ªè¯»å–

![image-20221231150939566](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20221231150939566.png)



### 2.5 NN and 2NN

#### 2.5.1 Working machanismï¼ˆå·¥ä½œæœºåˆ¶ï¼‰

NameNode ä¸­çš„å…ƒæ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­è¿˜æ˜¯ç£ç›˜ä¸­å‘¢ï¼Ÿ

1. å¦‚æœå­˜å‚¨åœ¨ç£ç›˜ä¸­ï¼Œéœ€è¦è¿›è¡Œéšæœºè®¿é—®ï¼Œä»¥åŠå“åº”å®¢æˆ·ç«¯è¯·æ±‚ï¼Œæ•ˆç‡éå¸¸ä½ï¼Œå› æ­¤ç¬¬ä¸€ä¸ªæ’é™¤
2. å¦‚æœå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œä¸€æ—¦æ–­ç”µæ•´ä¸ªé›†ç¾¤å°±æŒ‚äº†ï¼Œå› æ­¤éœ€è¦å¤‡ä»½å…ƒæ•°æ®--FsImage
3. å¦‚æœæ¯æ¬¡æ›´æ–°å…ƒæ•°æ®æ—¶ä¹Ÿæ›´æ–°FsImageé‚£æ•ˆç‡éå¸¸ä½ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªè¿½åŠ æ•°æ®æ–‡ä»¶--Edits
4. æ¯æ¬¡å…ƒæ•°æ®æ›´æ–°ï¼Œå°†æ›´æ–°çš„æ•°æ®å­˜å‚¨åˆ°Editsä¸­ï¼Œå› æ­¤<font color=#ff9f43>å…ƒæ•°æ®=FsImage+Edits</font> 

![image-20230101160158012](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20230101160158012.png)

#### 2.5.2 FsImage and Edits

NameNodeè¢«æ ¼å¼åŒ–åä¼šåœ¨ä»¥ä¸‹ç›®å½•äº§ç”Ÿä»¥ä¸‹å†…å®¹ 

![image-20230101160226740](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20230101160226740.png)

1. Fsimageï¼šå…ƒæ•°æ®çš„<font color=#ff9f43>æ°¸ä¹…æ£€æŸ¥ç‚¹</font> ï¼ŒåŒ…å«HDFSæ–‡ä»¶ç³»ç»Ÿä¸­æ‰€æœ‰ç›®å½•å’Œæ–‡ä»¶inodeçš„åºåˆ—åŒ–ä¿¡æ¯
2. Editsï¼šå­˜å‚¨HDFSæ–‡ä»¶ç³»ç»Ÿä¸­æ‰€æœ‰æ›´æ–°æ“ä½œçš„è·¯å¾„
3. seen_txid:ä¿å­˜çš„æ˜¯æœ€åä¸€ä¸ªedits_çš„æ•°å­—
4. æ¯æ¬¡NameNodeå¯åŠ¨çš„æ—¶å€™éƒ½ä¼šå°†Fsimageæ–‡ä»¶è¯»å…¥å†…å­˜ï¼ŒåŠ è½½Editsé‡Œé¢çš„æ›´æ–°æ“ä½œï¼Œå¯¹äºŒè€…è¿›è¡Œåˆå¹¶ï¼Œä¿è¯å…ƒæ•°æ®ä¿¡æ¯éƒ½æ˜¯æœ€æ–°çš„



### 2.6 DataNode

#### 2.6.1 Work machanism

1. å¯åŠ¨åï¼ŒDataNodeä¸»åŠ¨å‘NameNodeæ±‡æŠ¥å·¥ä½œï¼Œæ±‡æŠ¥è‡ªå·±çš„æ•°æ®å—ä¿¡æ¯
2. DataNodeæ‰«ææ‰€æœ‰å—ä¿¡æ¯çš„æ—¶é—´ï¼š6h
3. DataNodeæ±‡æŠ¥å°†æ‰€æœ‰å—ä¿¡æ¯æ±‡æŠ¥ç»™NNæ—¶é—´ï¼š6h
4. DNå‘Šè¯‰NNæˆ‘è¿˜æ´»ç€æ—¶é—´ï¼š3s
5. NNåˆ¤å®šDNä¸å¯ç”¨ï¼Œæ²¡æœ‰æ¥æ”¶åˆ°ä¿¡æ¯ï¼š10:30s

![image-20230101160331657](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20230101160331657.png)

#### 2.6.2 Data integrity

ä¿è¯æ•°æ®å®Œæ•´æ€§ç­–ç•¥

1. å½“DataNodeè¯»å–Blockçš„æ—¶å€™ï¼Œå®ƒä¼šè®¡ç®—CheckSum
2. CheckSumå¦‚æœä¸åˆ›å»ºæ—¶çš„Blockå€¼ä¸ä¸€æ ·ï¼Œè¯´æ˜Blockå·²ç»æŒ‚äº†
3. Clientè¯»å–å…¶ä»–DataNodeä¸Šçš„Block

å¸¸è§æ ¡éªŒç®—æ³•ï¼šcrcï¼ˆ32ï¼‰ã€md5ï¼ˆ128ï¼‰ã€shalï¼ˆ160ï¼‰

æ¯”è¾ƒlowçš„æœ‰å¥‡å¶æ ¡éªŒæ³•ï¼šè®¡ç®—ä¼ è¾“çš„æ•°æ®ä¸­æœ‰å¤šå°‘ä¸ª1ï¼Œå¦‚æœ1çš„ä¸ªæ•°ä¸ºå¶æ•°ï¼Œåˆ™æ ¡éªŒä½ä¸º0

![image-20230101160453308](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20230101160453308.png)



## ä¸‰ MAPREDUCE

### 3.1 Overview

#### 3.1.1 WWH

Mapreduceæ˜¯ä¸€ä¸ª<font color=#ff9f43>åˆ†å¸ƒå¼</font>è¿ç®—ç¨‹åºçš„<font color=#ff9f43>ç¼–ç¨‹æ¡†æ¶</font>ï¼Œæ ¸å¿ƒåŠŸèƒ½æ˜¯å°†ç”¨æˆ·å†™çš„<font color=#ff9f43>ä¸šåŠ¡é€»è¾‘ä»£ç </font>å’Œè‡ªèº«<font color=#ff9f43>é»˜è®¤ä»£ç </font>æ•´åˆæˆä¸€ä¸ª<font color=#ff9f43>å®Œæ•´çš„åˆ†å¸ƒå¼è¿ç®—ç¨‹åº</font>ï¼Œå¹¶å‘è¿è¡Œåœ¨ä¸€ä¸ªHadoopé›†ç¾¤ä¸Š

#### 3.1.2 Advantage

|      |      |
| ---- | ---- |
|      |      |
|      |      |
|      |      |



#### 3.1.3 Disadvantage



#### 3.1.4 Compose

#### 3.1.5 Example--WordCount

#### 3.1.6 Routine

### 3.2 Serialization

![image-20230101160957286](https://aaron-images-bed.oss-cn-hangzhou.aliyuncs.com/Typora/image-20230101160957286.png)

### 3.3 Core framework principles

InputFormat

OutFormat

Shuffle

Join

ETL

Conclusion

### 3.4 Compress(å‹ç¼©)

What

Traits

How



### 3.5 Common problems and solutions



## å›› YARN

